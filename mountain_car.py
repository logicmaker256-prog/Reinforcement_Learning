# ================================
# ğŸš— MountainCar Double DQN (å®‰å®šå®Œå…¨ç‰ˆ)
# ================================
!pip install gymnasium==0.29.1 moviepy > /dev/null

import gymnasium as gym
import numpy as np
import random
from collections import deque
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import imageio
from IPython.display import Video, display

# --- Double DQNãƒ¢ãƒ‡ãƒ«å®šç¾© ---
class DQN(nn.Module):
    def __init__(self, state_size, action_size):
        super(DQN, self).__init__()
        self.fc = nn.Sequential(
            nn.Linear(state_size, 128),
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, action_size)
        )
    def forward(self, x):
        return self.fc(x)

# --- Îµ-greedyã§è¡Œå‹•é¸æŠ ---
def select_action(state, epsilon):
    if random.random() < epsilon:
        return env.action_space.sample()
    else:
        with torch.no_grad():
            return torch.argmax(policy_net(torch.FloatTensor(state))).item()

# --- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆãƒãƒƒãƒˆæ›´æ–° ---
def update_target():
    target_net.load_state_dict(policy_net.state_dict())

# --- MountainCarç’°å¢ƒ ---
env = gym.make("MountainCar-v0")
state_size = env.observation_space.shape[0]
action_size = env.action_space.n

# --- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ»ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ ---
policy_net = DQN(state_size, action_size)
target_net = DQN(state_size, action_size)
update_target()
optimizer = optim.Adam(policy_net.parameters(), lr=0.001)
memory = deque(maxlen=50000)

# --- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ---
batch_size = 64
gamma = 0.99
epsilon = 1.0
epsilon_min = 0.05
epsilon_decay = 0.990
num_episodes = 1000
target_update = 10
rewards_log = []

# --- å­¦ç¿’ãƒ«ãƒ¼ãƒ— ---
for ep in range(num_episodes):
    state, _ = env.reset()
    total_reward = 0
    done = False

    while not done:
        action = select_action(state, epsilon)
        next_state, reward, terminated, truncated, _ = env.step(action)
        done = terminated or truncated

        # --- å ±é…¬ shapingï¼ˆç™»ã‚‹ã»ã©å ±é…¬ï¼‰ ---
        position, velocity = next_state
        reward = abs(position - (-0.5))
        if position >= 0.5:
            reward += 100  # ã‚´ãƒ¼ãƒ«ãƒœãƒ¼ãƒŠã‚¹

        # çµŒé¨“ã‚’ä¿å­˜
        memory.append((state, action, reward, next_state, done))
        state = next_state
        total_reward += reward

        # --- Double DQN ã®æ›´æ–° ---
        if len(memory) > batch_size:
            minibatch = random.sample(memory, batch_size)
            states, actions, rewards, next_states, dones = zip(*minibatch)

            states = torch.FloatTensor(states)
            actions = torch.LongTensor(actions).unsqueeze(1)
            rewards = torch.FloatTensor(rewards)
            next_states = torch.FloatTensor(next_states)
            dones = torch.FloatTensor(dones)

            # (1) ç¾åœ¨ã®Qå€¤
            q_values = policy_net(states).gather(1, actions).squeeze(1)

            # (2) Double DQNã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨ˆç®—
            next_actions = policy_net(next_states).argmax(1).unsqueeze(1)
            next_q_values = target_net(next_states).gather(1, next_actions).squeeze(1)
            targets = rewards + gamma * next_q_values * (1 - dones)

            # (3) æå¤±è¨ˆç®—ãƒ»æ›´æ–°
            loss = nn.functional.mse_loss(q_values, targets)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

    # --- Îµæ¸›è¡° ---
    epsilon = max(epsilon_min, epsilon * epsilon_decay)
    rewards_log.append(total_reward)

    if ep % target_update == 0:
        update_target()

    print(f"Ep {ep:3d}  Reward={total_reward:7.2f}  Eps={epsilon:.3f}")

env.close()

# --- å­¦ç¿’æ›²ç·šè¡¨ç¤º ---
plt.plot(rewards_log)
plt.xlabel("Episode")
plt.ylabel("Total Reward")
plt.title("ğŸ”ï¸ Double DQN Training Reward (MountainCar-v0)")
plt.grid()
plt.show()

# ==========================
# ğŸ¥ å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§å‹•ç”»æ’®å½±
# ==========================
video_path = "mountaincar_double_dqn.mp4"
env = gym.make("MountainCar-v0", render_mode="rgb_array")
frames = []

state, _ = env.reset()
done = False
while not done:
    frame = env.render()
    frames.append(frame)
    action = select_action(state, epsilon=0.0)  # å®Œå…¨å­¦ç¿’æ¸ˆã¿ã§å®Ÿè¡Œ
    next_state, reward, terminated, truncated, _ = env.step(action)
    done = terminated or truncated
    state = next_state

env.close()
imageio.mimsave(video_path, frames, fps=30)

# --- Colabä¸Šã§å‹•ç”»å†ç”Ÿ ---
display(Video(video_path, embed=True))